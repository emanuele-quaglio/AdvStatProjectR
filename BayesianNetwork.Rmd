---
title: "R Notebook"
output: html_notebook
---

```{r}
#install.packages("tidyverse")
#install.packages("conflicted")
#install.packages("ggraph")
#install.packages("foreach")
#install.packages("doParallel")
library(tidyverse)
library(igraph)
library(ggraph)
library(foreach)
library(doParallel)
library(conflicted)
conflicts_prefer(dplyr::filter)





```

```{r}
print_grouped_df <- function(grouped_df) {
  # Loop over each group
  groups <- group_split(grouped_df)
  group_vars <- group_vars(grouped_df)
  
  for (i in seq_along(groups)) {
    # Get the current group data
    current_group <- groups[[i]]
    
    # Extract the values of the grouping variables for this group
    group_keys <- current_group[1, group_vars, drop = FALSE]
    
    # Print the group header with key values
    cat("\n==== Group:", paste(names(group_keys), "=", as.character(group_keys), collapse = ", "), "====\n")
    
    # Print the current group
    print(current_group)
  }
}


options(paged.print = FALSE)


# f_20 and helper functions

Prod_j<-function(df, i, parents, r){
    if(!is.null(parents) & length(parents)!=0){
      ret<-df %>%
              group_by(across(all_of(parents))) %>%
              summarise(N_ij = n()) %>% 
              mutate(ratio = factorial(r[i] - 1) / factorial(N_ij + r[i] - 1))
    }else{
      ret <-df %>%
              summarise(N_ij = n()) %>% 
              mutate(ratio = factorial(r[i] - 1) / factorial(N_ij + r[i] - 1))
    }
  return(prod(ret$ratio))
  }
  
Prod_jk<-function(df, i, parents){
  if(length(c(parents, i))!=0){
    ret<-(df %>%
            group_by(across(all_of(c(parents, i)))) %>%
            summarise(count = n()) %>%
            mutate(factorial_count = factorial(count)))
    return(prod(ret$factorial_count))
  }
}

f_20<-function(original_df, i, parents, r){
  prod_g_ij=Prod_j(original_df, i, parents, r)
  prod_f_ijk=Prod_jk(original_df, i, parents)
  return (prod_g_ij*prod_f_ijk)
}

# Algorithm
k2_algorithm <- function(data, nodes, max_parents = 10) {
  
  # Initialize the network
  network <- setNames(vector("list", length(nodes)), nodes)
  network[[nodes[1]]]<-character(0)
  #network[] <- lapply(network, function(x) character(0))
  #E' PROBABILE CHE CI VOGLIA QUALCOSA DI PIU'SPECIFICO DI UNA LIST, ES. net.dag <- empty.graph(nodes=nodes) 
  
  # Detect the number of available cores
  numCores <- parallel::detectCores()
  
  # Create a cluster with the desired number of cores
  cl <- makeCluster(numCores - 1)  # Use one less core than available
  
  # Register the cluster for parallel processing
  registerDoParallel(cl)
  # Ensure cluster is stopped even if an error occurs
  on.exit(stopCluster(cl))
  # Parallel execution example
  #stopCluster(cl)
  
  #Calculate r_i
  r<-map_int(data, n_distinct)
  # Iterate over each node
  result<-foreach (i = 2:length(nodes), .combine = 'list', .packages = c('dplyr', 'purrr'), .export = c('Prod_jk', 'Prod_j', 'f_20')) %dopar% {
     # Calculate r_i:

    parents <- c()
    score_old <- f_20(data, i, parents, r)
    proceed <- TRUE
    while (proceed && length(parents) < max_parents) {

      # Find the best candidate parent
      best_parent <- NULL
      best_score <- score_old

      for (z in setdiff(1:(i-1), parents)) {
        parents_trial<-c(parents, z)
        best_score <- f_20(data, i, parents_trial, r)
        if (best_score > score_old) { 
          best_parent <- z
          score_old <- best_score
        }
      }

      # Update parents and score if necessary
      if (!is.null(best_parent)) {
        parents <- c(parents, best_parent)
        score_old <- best_score
      } else {
        proceed <- FALSE
      }
    }
    
    # Return the parents for the current node
    return(list(node = nodes[i], foundparents = if(length(parents) == 0) character(0) else sapply(parents, function(el) nodes[el])))

  }
  
  # Assign results to the network
  for (res in result) {
    network[[res$node]] <- res$foundparents
  }
  
  return(network)
}

```

```{r}
print_network<-function(network){
  # Crea un dataframe con tutti i nodi
  nodes <- tibble(node = names(network))
  
  # Crea un dataframe con gli archi esistenti (quelli t.c. nodi_non_isolati <- V(graph)[degree(graph) > 0])
  edges_existing <- tibble(
    from = unlist(network),
    to = rep(names(network), sapply(network, length))
  )
  
  # Identifica i nodi isolati
  nodes_isolated <- nodes %>%
    filter(!(node %in% c(edges_existing$from, edges_existing$to)))
  
  # Crea un dataframe con gli archi autoreferenziali per i nodi isolati
  edges_isolated <- tibble(
    from = nodes_isolated$node,
    to = nodes_isolated$node
  )

# Combina i due dataframe degli archi
edges <- bind_rows(edges_existing, edges_isolated)
  # Creazione del grafo
  graph <- graph_from_data_frame(edges, directed = TRUE)
  # Visualizzazione del grafo
  ggraph(graph, layout = "tree") +
    #coord_cartesian(xlim = c(-0.6, 0.6), ylim = c(-0.2, 1.1)) +
    geom_node_point(shape = 21, size = 20, color = "green") +
    geom_node_text(aes(label = name), repel = FALSE, fontface = "bold", nudge_x = +0, nudge_y = +0) +
    geom_edge_link(arrow = arrow(length = unit(0.2, "inches"), type = "closed"),
                   end_cap = circle(), start_cap = circle()) +
    #theme_graph() +
    labs(title = "Rete Bayesiana")
}



```


```{r}
trial_df <- data.frame(
  x1 = c(1, 1, 0, 1, 0, 0, 1, 0, 1, 0),
  x2 = c(0, 1, 0, 1, 0, 1, 1, 0, 1, 0),
  x3 = c(0, 1, 1, 1, 0, 1, 1, 0, 1, 0)
)

trial_df_zeros <- data.frame(
  x1 = c(0, 1, 0, 1, 0, 0, 0, 0, 1, 0),
  x2 = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
  x3 = c(0, 1, 0, 1, 0, 1, 1, 0, 1, 0)
)
```


```{r}
network<-k2_algorithm(trial_df_zeros, c("x1", "x2", "x3"), 2)
print(network)
print_network(network)
```



