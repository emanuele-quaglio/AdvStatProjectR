{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b928c7ab",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"R Notebook\"\n",
    "output: html_notebook\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#install.packages(\"tidyverse\")\n",
    "#install.packages(\"conflicted\")\n",
    "#install.packages(\"ggraph\")\n",
    "#install.packages(\"foreach\")\n",
    "#install.packages(\"doParallel\")\n",
    "#install.packages(\"bnlearn\")\n",
    "#install.packages(\"actuar\")\n",
    "#install.packages(\"BiocManager\")\n",
    "#BiocManager::install(\"Rgraphviz\")\n",
    "library(tidyverse)\n",
    "library(igraph)\n",
    "library(ggraph)\n",
    "library(foreach)\n",
    "library(doParallel)\n",
    "library(conflicted)\n",
    "library(bnlearn)\n",
    "library(actuar, include.only = c(\"rztbinom\"))\n",
    "library(Rgraphviz)\n",
    "#library(dplyr, include.only = c(\"select\", \"mutate\")\n",
    "\n",
    "conflicts_prefer(dplyr::filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f5f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "rds_name<-function(title){\n",
    "  # For naming saved files with a time-stamp\n",
    "  return(paste0(title,as.numeric(Sys.time()) * 1000, '.rds'))\n",
    "}\n",
    "print_grouped_df <- function(grouped_df) {\n",
    "  # Loop over each group\n",
    "  groups <- group_split(grouped_df)\n",
    "  group_vars <- group_vars(grouped_df)\n",
    "  \n",
    "  for (i in seq_along(groups)) {\n",
    "    # Get the current group data\n",
    "    current_group <- groups[[i]]\n",
    "    \n",
    "    # Extract the values of the grouping variables for this group\n",
    "    group_keys <- current_group[1, group_vars, drop = FALSE]\n",
    "    \n",
    "    # Print the group header with key values\n",
    "    cat(\"\\n==== Group:\", paste(names(group_keys), \"=\", as.character(group_keys), collapse = \", \"), \"====\\n\")\n",
    "    \n",
    "    # Print the current group\n",
    "    print(current_group)\n",
    "  }\n",
    "}\n",
    "\n",
    "create_bn_dag <- function(dag) {\n",
    "    # Turn our dag object into bnlearn compatible object\n",
    "    net_nodes <- names(dag)\n",
    "\n",
    "    our.net.dag <- empty.graph(net_nodes)\n",
    "\n",
    "    net_parents <- dag\n",
    "   \n",
    "    for (node in net_nodes) {\n",
    "        if (all(net_parents[node] != \"character(0)\")) {\n",
    "        for (single_parent in net_parents[[node]]) {\n",
    "            our.net.dag <- set.arc(our.net.dag, from = single_parent, to = node)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    return(our.net.dag)\n",
    "}\n",
    "\n",
    "options(paged.print = FALSE)\n",
    "\n",
    "logfactorial<-function(n){\n",
    "  # Calculate logarithm of factorial of a number\n",
    "  \n",
    "  if(n>=2){\n",
    "    res<-sum(log(seq(2, n)))\n",
    "  }else{\n",
    "    res<-0\n",
    "  }\n",
    "  return(res)\n",
    "}\n",
    "\n",
    "\n",
    "Prod_j <- function(df, i, parents, r) {\n",
    "  # Helper Function for f_20: Prod_j\n",
    "  \n",
    "  #print(paste(\"Running Prod_j with i =\", i))\n",
    "  #print(paste(\"Parents:\", paste(parents, collapse = \", \")))\n",
    "  \n",
    "  if (!is.null(parents) & length(parents) != 0) {\n",
    "    #print(\"Grouping by parents...\")\n",
    "    ret <- df %>%\n",
    "      group_by(across(all_of(parents))) %>%\n",
    "      summarise(N_ij = n(), .groups = \"keep\") %>% \n",
    "      mutate(ratio= logfactorial(r[i] - 1)- logfactorial(N_ij + r[i] - 1))\n",
    "  } else {\n",
    "    #print(\"No parents to group by...\")\n",
    "    ret <- df %>%\n",
    "      summarise(N_ij = n(), .groups = \"keep\") %>% \n",
    "      mutate(ratio= logfactorial(r[i] - 1) - logfactorial(N_ij + r[i] - 1))\n",
    "  }\n",
    "  \n",
    "  #print(\"Intermediate result of Prod_j:\")\n",
    "  #print(ret)\n",
    "  \n",
    "  result <- sum(ret$ratio)\n",
    "  #print(paste(\"Result of Prod_j:\", result))\n",
    "  return(result)\n",
    "}\n",
    "\n",
    "\n",
    "Prod_jk <- function(df, i, parents) {\n",
    "  # Helper Function for f_20: Prod_jk\n",
    "  \n",
    "  #print(paste(\"Running Prod_jk with i =\", i))\n",
    "  #print(paste(\"Parents:\", paste(parents, collapse = \", \")))\n",
    "  \n",
    "  if (length(c(parents, i)) != 0) {\n",
    "    #print(\"Grouping by parents and i...\")\n",
    "    ret <- df %>%\n",
    "      group_by(across(all_of(c(parents, i)))) %>%\n",
    "      summarise(count = n(), .groups = \"keep\") %>%\n",
    "      mutate(factorial_count = logfactorial(count))\n",
    "    \n",
    "    #print(\"Intermediate result of Prod_jk:\")\n",
    "    #print(ret)\n",
    "    \n",
    "    result <- sum(ret$factorial_count)\n",
    "    #print(paste(\"Result of Prod_jk:\", result))\n",
    "    return(result)\n",
    "  } else {\n",
    "    #print(\"No grouping needed for Prod_jk.\")\n",
    "    return(1)\n",
    "  }\n",
    "}\n",
    "\n",
    "f_20 <- function(original_df, i, parents, r) {\n",
    "  # Calculates the K2-score of a node given a dataframe, the index of a node, and the vector r_i of dinstict values for each i-th column\n",
    "  \n",
    "  #print(paste(\"Running f_20 with i =\", i))\n",
    "  #print(paste(\"Parents:\", paste(parents, collapse = \", \")))\n",
    "  \n",
    "  prod_g_ij <- Prod_j(original_df, i, parents, r)\n",
    "  prod_f_ijk <- Prod_jk(original_df, i, parents)\n",
    "  \n",
    "  #print(paste(\"prod_g_ij:\", prod_g_ij))\n",
    "  #print(paste(\"prod_f_ijk:\", prod_f_ijk))\n",
    "  \n",
    "  result <- prod_g_ij + prod_f_ijk \n",
    "  #print(paste(\"Result of f_20:\", result))\n",
    "  \n",
    "  return(result)\n",
    "}\n",
    "\n",
    "\n",
    "k2_algorithm <- function(data, nodes=NULL, max_parents = NULL) {\n",
    "  \n",
    "  # Return list with best network and associated score, given:\n",
    "  # - a dataframe\n",
    "  # - a vector of character nodes (optional; in absence, gets ordering from the dataframe columns ordering)\n",
    "  # - a maximum number of parents (optional; in absence, assumes the as maximum number the total number of nodes - 1)\n",
    "\n",
    "  if(is.null(nodes)){\n",
    "    nodes<-names(data)\n",
    "  }\n",
    "  if(is.null(max_parents)){\n",
    "    max_parents<-length(nodes)-1\n",
    "  }\n",
    "  # Initialize the network\n",
    "  network <- setNames(vector(\"list\", length(nodes)), nodes)\n",
    "  network[[nodes[1]]]<-character(0)\n",
    "  \n",
    "  # Detect the number of available cores\n",
    "  numCores <- parallel::detectCores()\n",
    "  # Create a cluster with the desired number of cores\n",
    "  cl <- makeCluster(numCores - 1)  # Use one less core than available\n",
    "  # Register the cluster for parallel processing\n",
    "  registerDoParallel(cl)\n",
    "  # Ensure cluster is stopped even if an error occurs\n",
    "  on.exit(stopCluster(cl))\n",
    "  #Calculate r_i\n",
    "  r<-map_int(data, n_distinct)\n",
    "  \n",
    "  # Iterate over each node. This is parallelized according to available number of cores\n",
    "  result<-foreach (i = 2:length(nodes), .combine = 'c', .packages = c('dplyr', 'purrr'), .export = c('logfactorial', 'Prod_jk', 'Prod_j', 'f_20')) %dopar% {\n",
    "     # Calculate r_i:\n",
    "\n",
    "    parents <- c()\n",
    "    score_old <- f_20(data, i, parents, r)\n",
    "    proceed <- TRUE\n",
    "    while (proceed & length(parents) < max_parents) {\n",
    "\n",
    "      # Find the best candidate parent\n",
    "      best_parent <- NULL\n",
    "      best_score <- score_old\n",
    "\n",
    "      for (z in base::setdiff(1:(i-1), parents)) {\n",
    "        parents_trial<-c(parents, z)\n",
    "        best_score <- f_20(data, i, parents_trial, r)\n",
    "        if (best_score > score_old) { \n",
    "          best_parent <- z\n",
    "          score_old <- best_score\n",
    "        }\n",
    "      }\n",
    "      # Update parents and score if necessary\n",
    "      if (!is.null(best_parent)) {\n",
    "        parents <- c(parents, best_parent)\n",
    "        score_old <- best_score\n",
    "      } else {\n",
    "        proceed <- FALSE\n",
    "      }\n",
    "    }\n",
    "    # Return the parents for the current node\n",
    "    return(list(list(node = nodes[i], foundparents = if(length(parents) == 0) character(0) else sapply(parents, function(el) nodes[el]), best_score=best_score)))\n",
    "  }\n",
    "  # Assign results to the network\n",
    "  total_best_score<-0\n",
    "  for (res in result) {\n",
    "    network[[res$node]] <- res$foundparents\n",
    "    total_best_score<-total_best_score+res$best_score\n",
    "  }\n",
    "  \n",
    "  return(list(dag=network, score=total_best_score))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e393c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "print_network<-function(network, layout = \"auto\"){ \n",
    "  # Create dataframe with all nodes\n",
    "  nodes <- tibble(node = names(network)) \n",
    "   \n",
    "  # Create dataframe with existing arcs (nodes_non_isolated <- V(graph)[degree(graph) > 0]) \n",
    "  edges_existing <- tibble( \n",
    "    from = unlist(network), \n",
    "    to = rep(names(network), sapply(network, length)) \n",
    "  ) \n",
    "   \n",
    "  # Identify isolated nodes \n",
    "  nodes_isolated <- nodes %>% \n",
    "    filter(!(node %in% c(edges_existing$from, edges_existing$to))) \n",
    "   \n",
    "  # Creates dataframe with self-referenced arcs for isolated nodes (needed for plotting technical reasons)\n",
    "  edges_isolated <- tibble( \n",
    "    from = nodes_isolated$node, \n",
    "    to = nodes_isolated$node \n",
    "  ) \n",
    "     \n",
    "  # Combines the two dataframes \n",
    "  edges <- bind_rows(edges_existing, edges_isolated) \n",
    " \n",
    "  # DAG creation\n",
    "  graph <- graph_from_data_frame(edges, directed = TRUE) \n",
    "  ggraph(graph, layout = layout) + \n",
    "    geom_node_point(shape = 21, size = 20, color = \"green\") + \n",
    "    geom_node_text(aes(label = name), repel = FALSE, fontface = \"bold\", nudge_x = +0, nudge_y = +0) + \n",
    "    geom_edge_link(arrow = arrow(length = unit(0.2, \"inches\"), type = \"closed\"), \n",
    "                   end_cap = circle(), start_cap = circle())\n",
    "                   #, curve = 0.2) + \n",
    "    #labs(title = \"Rete Bayesiana\") \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "plot_dag<-function(dag){\n",
    "  # Plots dag with graphviz library\n",
    "  graphviz.plot(create_bn_dag(dag))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8984a176",
   "metadata": {},
   "source": [
    "Simple datasets for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc6af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "trial_df <- data.frame(\n",
    "  x1 = c(1, 1, 0, 1, 0, 0, 1, 0, 1, 0),\n",
    "  x2 = c(0, 1, 0, 1, 0, 1, 1, 0, 1, 0),\n",
    "  x3 = c(0, 1, 1, 1, 0, 1, 1, 0, 1, 0)\n",
    ")\n",
    "\n",
    "trial_df_zeros <- data.frame(\n",
    "  x1 = c(0, 1, 0, 1, 0, 0, 0, 0, 1, 0),\n",
    "  x2 = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "  x3 = c(0, 1, 0, 1, 0, 1, 1, 0, 1, 0),\n",
    "  x4 = c(0, 1, 1, 1, 0, 1, 1, 0, 1, 0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1692bd3c",
   "metadata": {},
   "source": [
    "Test k2_algorithm on simple dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e339039",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "network<-k2_algorithm(trial_df)\n",
    "print(network[['dag']])\n",
    "print(network[['score']])\n",
    "print_network(network[['dag']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b5f409",
   "metadata": {},
   "source": [
    "Now we load and explore three dataset, used in the following analysis. \n",
    "Respectively: asia, child and sachs.\n",
    "\n",
    "Asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70491da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "asia <- read_csv('https://www.ccd.pitt.edu/wiki/images/ASIA10k.csv')\n",
    "head(asia)\n",
    "asia <- asia |> select(asia, smoke, tub, lung, either, bronc, xray, dysp)\n",
    "\n",
    "# This is the ground-truth expected network associated to the dataset.\n",
    "true_dag.asia<- model2network(\"[asia][smoke][tub|asia][lung|smoke][bronc|smoke][dysp|bronc:either][either|tub:lung][xray|either]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeaa0ce",
   "metadata": {},
   "source": [
    "Child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0858e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "child <- read_csv('https://www.ccd.pitt.edu/wiki/images/CHILD10k.csv')\n",
    "child <- child |> select(BirthAsphyxia, Disease, Sick, DuctFlow, CardiacMixing, LungParench, LungFlow, LVH, Age, Grunting, HypDistrib, HypoxiaInO2, CO2, ChestXray, LVHreport, GruntingReport, LowerBodyO2, RUQO2, CO2Report, XrayReport)\n",
    "head(child)\n",
    "\n",
    "# This is the ground-truth expected network associated to the dataset\n",
    "true_dag.child<-model2network(\"[BirthAsphyxia][Disease|BirthAsphyxia][Sick|Disease][DuctFlow|Disease][CardiacMixing|Disease][LungParench|Disease][LungFlow|Disease][LVH|Disease][Age|Disease:Sick][Grunting|Sick:LungParench][HypDistrib|DuctFlow:CardiacMixing][HypoxiaInO2|CardiacMixing:LungParench][CO2|LungParench][ChestXray|LungParench:LungFlow][LVHreport|LVH][GruntingReport|Grunting][LowerBodyO2|HypDistrib:HypoxiaInO2][RUQO2|HypoxiaInO2][CO2Report|CO2][XrayReport|ChestXray]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7535a9",
   "metadata": {},
   "source": [
    "Sachs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "sachs <- read_csv('https://www.ccd.pitt.edu/wiki/images/SACHS10k.csv')\n",
    "sachs <- sachs |> select(PKC, Plcg, PKA, PIP3, Raf, Jnk, P38, PIP2, Mek, Erk, Akt)\n",
    "head(sachs)\n",
    "\n",
    "# This is the ground-truth expected network associated to the dataset\n",
    "true_dag.sachs <- model2network(\"[PKC][PKA|PKC][Raf|PKC:PKA][Mek|PKC:PKA:Raf][Erk|Mek:PKA][Akt|Erk:PKA][P38|PKC:PKA][Jnk|PKC:PKA][Plcg][PIP3|Plcg][PIP2|Plcg:PIP3]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ed0b18",
   "metadata": {},
   "source": [
    "We defined for global usage some list and vectors associated to important features of each dataset (name, expected DAG, maximum number of parents present, univocal color for clearer plotting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef0ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "dataset_names<-c('asia', 'child', 'sachs')\n",
    "datasets<-list(asia=asia, child=child, sachs=sachs)\n",
    "true_dags<-list(asia=true_dag.asia, child=true_dag.child, sachs=true_dag.sachs)\n",
    "true_max_parents<-list(asia=2, child=2, sachs=3)\n",
    "dataset_colors<-c(asia='goldenrod', child='seagreen', sachs='firebrick')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d48496",
   "metadata": {},
   "source": [
    "##Let's first constrain the nodes ordering of each network according to the ground truth DAG's expected.\n",
    "\n",
    "###Let's first test our k2 algorithm plotting the resulted best network, for all datasets.\n",
    "Constrained max number of parents according to ground truth expected DAG's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "for(dataset_name in dataset_names){\n",
    "  network<-k2_algorithm(datasets[[dataset_name]], max_parents = true_max_parents[[dataset_name]] )\n",
    "  plot_dag(network[['dag']])\n",
    "  #graphviz.compare(true_dags[[dataset_name]], create_bn_dag((network[['dag']])))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7edc565",
   "metadata": {},
   "source": [
    "Unconstrained max number of parents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46abfeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "for(dataset_name in dataset_names){\n",
    "  network<-k2_algorithm(datasets[[dataset_name]] )\n",
    "  plot_dag(network[['dag']])\n",
    "  #graphviz.compare(true_dags[[dataset_name]], create_bn_dag((network[['dag']])))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa69d47",
   "metadata": {},
   "source": [
    "###Comparison between predicted networks and ground truth (expected) networks, as a function of dataset size.\n",
    "Error is calculated as the complementary of the F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6440fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "f1_error<-function(my_dag, true_dag, n_true_edges=NULL){\n",
    "  # Calculate \"error\" with respect to assumed \"true\" DAG as 1 - F1_score\n",
    "  \n",
    "  if(is.null(n_true_edges)){\n",
    "    n_true_edges<-nrow(arcs(true_dag))\n",
    "  }\n",
    "  dag_compare <- bnlearn::compare(true_dag, my_dag) \n",
    "  precision<-as.numeric(dag_compare[\"tp\"])/(as.numeric(dag_compare[\"tp\"])+as.numeric(dag_compare[\"fp\"])) \n",
    "  recall<-as.numeric(dag_compare[\"tp\"])/n_true_edges  \n",
    "  f1<-2*precision*recall/(precision+recall) \n",
    "  return(1-f1) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe9524",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "error_vs_data_size<-function(network_learner, data_df, true_dag, logscale=FALSE){\n",
    "  # Plot (and return x,y coordinates of the plot) error as a function of increasing dataset size\n",
    "  # Arguments are:\n",
    "  # - network learner: k2_algorithm or alternative with same interface\n",
    "  # - data_df: dataset as a dataframe\n",
    "  # - true_dag: expected, \"ground truth\", DAG associated to dataset\n",
    "  # - logscale (optional): set logscale for x-axis\n",
    "  \n",
    "  spanned=c(10,20,30,50,100,200,300, 500, 1000, 5000, 10000)\n",
    "  errors=vector('list', length(spanned))\n",
    "  for(i in 1:length(spanned)){\n",
    "    my_dag<-create_bn_dag(network_learner(head(data_df, spanned[i]))[['dag']])\n",
    "    errors[[i]]<-f1_error(my_dag, true_dag)\n",
    "  }\n",
    "  if(logscale){\n",
    "    plot(spanned[1:length(errors)],errors,xlab='Dataset size (logscale)',ylab='Error',type='l',col='blue', log='x')\n",
    "  }else{\n",
    "    plot(spanned[1:length(errors)],errors,xlab='Dataset size',ylab='Error',type='l',col='blue') \n",
    "  }\n",
    "  return(list(x=spanned[1:length(errors)], y=errors))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95e72fa",
   "metadata": {},
   "source": [
    "First case: initialization with expected nodes ordering and expected max number of parents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c09d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "constrained_nodes_parents_error_vs_datasize<-setNames(vector(\"list\", 3), c(\"asia\", \"child\", \"sachs\"))\n",
    "CNPEVD<-constrained_nodes_parents_error_vs_datasize\n",
    "for( dataset_name in c('asia','child','sachs')){\n",
    "  CNPEVD[[dataset_name]]<-error_vs_data_size(function(data)(k2_algorithm(data, max_parents = 2)), datasets[[dataset_name]], true_dags[[dataset_name]], logscale=TRUE)\n",
    "}\n",
    "saveRDS(CNPEVD, file=rds_name('CNPEVD'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d929ba06",
   "metadata": {},
   "source": [
    "Second case: initialization with expected nodes ordering but 'unconstrained' number of parents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ee13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#constrained_nodes_error_vs_datasize<-error_vs_data_size(k2_algorithm, child, true_dag.child)\n",
    "constrained_nodes_error_vs_datasize<-setNames(vector(\"list\", 3), c(\"asia\", \"child\", \"sachs\"))\n",
    "CNEVD<-constrained_nodes_error_vs_datasize\n",
    "for( dataset_name in c('asia','child','sachs')){\n",
    "  CNEVD[[dataset_name]]<-error_vs_data_size(k2_algorithm, datasets[[dataset_name]], true_dags[[dataset_name]], logscale=TRUE)\n",
    "}\n",
    "saveRDS(CNEVD, file=rds_name('CNEVD'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e577f3c6",
   "metadata": {},
   "source": [
    "Plot all datasets in one:\n",
    "\n",
    "Constrained parents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356671df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "spanned <- c(10, 20, 30, 50, 100, 200, 300, 500, 1000, 5000, 10000) \n",
    "endrange <- 9 \n",
    "\n",
    "# Set graphical parameters\n",
    "par(mgp = c(1.5, 0.5, 0))  # Adjust mgp to reduce space (default is c(3, 1, 0)) \n",
    "# Plot the 'asia' dataset with filled dots \n",
    "plot(CNPEVD[['asia']][['x']][1:endrange],  \n",
    "     CNPEVD[['asia']][['y']][1:endrange],  \n",
    "     type='b',  \n",
    "     ylim=c(0,1),  \n",
    "     ylab=\"Error\",  \n",
    "     xlab=\"Dataset size\",  \n",
    "     col='goldenrod',  \n",
    "     pch=16)  # pch=16 for filled circles \n",
    " \n",
    "# Define datasets and colors \n",
    "dataset_name <- c('child', 'sachs') \n",
    "cols <- c(\"seagreen\", \"firebrick\") \n",
    " \n",
    "# Loop through and add lines for 'child' and 'sachs' with filled dots \n",
    "for(j in 1:length(dataset_name)) { \n",
    "  lines(CNPEVD[[dataset_name[j]]][['x']][1:endrange],  \n",
    "        CNPEVD[[dataset_name[j]]][['y']][1:endrange],  \n",
    "        col=cols[j],  \n",
    "        type='b',  \n",
    "        pch=16)  # pch=16 for filled circles \n",
    "} \n",
    "\n",
    "# Add legend with matching colors \n",
    "legend(x='topright', legend=c('asia', 'child', 'sachs'), col=c('goldenrod', 'seagreen', 'firebrick'), lty=1, pch=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585dbbd0",
   "metadata": {},
   "source": [
    "Unconstrained parents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d292aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "spanned <- c(10, 20, 30, 50, 100, 200, 300, 500, 1000, 5000, 10000) \n",
    "endrange <- 9 \n",
    "\n",
    "# Set graphical parameters\n",
    "par(mgp = c(1.5, 0.5, 0))  # Adjust mgp to reduce space (default is c(3, 1, 0)) \n",
    "# Plot the 'asia' dataset with filled dots \n",
    "plot(CNEVD[['asia']][['x']][1:endrange],  \n",
    "     CNEVD[['asia']][['y']][1:endrange],  \n",
    "     type='b',  \n",
    "     ylim=c(0,1), \n",
    "     ylab=\"Error\",  \n",
    "     xlab=\"Dataset size\",  \n",
    "     col='goldenrod',  \n",
    "     pch=16)  # pch=16 for filled circles \n",
    " \n",
    "# Define datasets and colors \n",
    "dataset_name <- c('child', 'sachs') \n",
    "cols <- c(\"seagreen\", \"firebrick\") \n",
    " \n",
    "# Loop through and add lines for 'child' and 'sachs' with filled dots \n",
    "for(j in 1:length(dataset_name)) { \n",
    "  lines(CNEVD[[dataset_name[j]]][['x']][1:endrange],  \n",
    "        CNEVD[[dataset_name[j]]][['y']][1:endrange],  \n",
    "        col=cols[j],  \n",
    "        type='b',  \n",
    "        pch=16)  # pch=16 for filled circles \n",
    "} \n",
    "\n",
    "# Add legend with matching colors \n",
    "legend(x='topright', legend=c('asia', 'child', 'sachs'), col=c('goldenrod', 'seagreen', 'firebrick'), lty=1, pch=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9073a833",
   "metadata": {},
   "source": [
    "## Now we remove the nodes ordering constraint, searching in the permutation space for the highest score dag.\n",
    "\n",
    "\n",
    "Function that finds best nodes ordering by uniformly sampling the corresponding permutation space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c35151",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "bn_uniform<-function(score_function, data_df, n_iter){\n",
    "  # Arguments:\n",
    "  # - score_function: a function like k2_algorithm, that given an ordering and data, gives as output the list(network,score) of the corresponding best bayesian network\n",
    "  # - data_df: dataset as a dataframe\n",
    "  # - n_iter: number of random samples from permutation space\n",
    "  nodes<-names(data_df)\n",
    "  chain<-vector('list', n_iter)\n",
    "  for(i in 1:n_iter){\n",
    "    best_network<-score_function(data_df)\n",
    "    chain[[i]]<-list(nodes=nodes, dag=best_network[['dag']], score=best_network[['score']])\n",
    "    nodes<-sample(nodes)\n",
    "    data_df <- data_df |> select(all_of(nodes))\n",
    "  }\n",
    "  max_index<-which.max(lapply(chain, function(el)(el[['score']])))\n",
    "  return(list(chain=chain, best=chain[[max_index]]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedcb551",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "n_iter<-5\n",
    "start.time<-proc.time()\n",
    "bn_uniform_result<-bn_uniform(k2_algorithm, sachs, n_iter)\n",
    "end.time<-proc.time()\n",
    "cat('bn_ordering_sampling duration' ,n_iter, 'iterations: ', end.time-start.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "saveRDS(bn_uniform_result, file=rds_name('unif_ordering'))\n",
    "object.size(bn_uniform_result[['chain']])\n",
    "network_dag<-bn_uniform_result[['best']][['dag']]\n",
    "chain_scores<-sapply(bn_uniform_result[['chain']], function(el)(el[['score']]))\n",
    "chain_nodes_orderings<-lapply(bn_uniform_result[['chain']], function(el)(el[['nodes']]))\n",
    "print(bn_uniform_result[['best']][['score']])\n",
    "print_network(network_dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c659e47f",
   "metadata": {},
   "source": [
    "Function (preceded bu some additional helper functions) that finds best nodes ordering with mcmc-metropolis-hastings-like procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "uniform_transposition_generator<-function(nodes){\n",
    "  # Generates new nodes vector that differs, from the given one, by one random transposition of two nodes\n",
    "  \n",
    "  # Choose two distinct indices randomly\n",
    "  indices <- sample(seq_along(nodes), 2)\n",
    "  \n",
    "  # Swap the elements at these indices\n",
    "  transposed_nodes <- nodes\n",
    "  temp <- transposed_nodes[indices[1]]\n",
    "  transposed_nodes[indices[1]] <- transposed_nodes[indices[2]]\n",
    "  transposed_nodes[indices[2]] <- temp\n",
    "  return(transposed_nodes)\n",
    "}\n",
    "ztbinom_permutation_generator<-function(nodes,  mean=1,variance=4/5){ \n",
    "  # Generates new nodes vector that differs, from the given one, by k random transpositions of two nodes, k drawn from zero-truncated binomial distribution (its parameters given as optional arguments)\n",
    "  \n",
    "  p<-(1-(variance/mean)) \n",
    "  n<-mean/p \n",
    "  n_transpositions<-rztbinom(1,size=n,prob=p) \n",
    "  #x<-seq(1,n,by=1) \n",
    "  #plot(x,dztbinom(x,size=n,prob=p)) \n",
    "  #perform the transposition \n",
    "  temp_nodes<-nodes     \n",
    "  for(j in 1:n_transpositions){ \n",
    "    temp_nodes<-uniform_transposition_generator(temp_nodes)   \n",
    "  } \n",
    "  transposed_nodes<-temp_nodes \n",
    "  return(transposed_nodes)   \n",
    "}\n",
    "\n",
    "bn_mcmc<-function(proposal_generator, score_function, data_df, n_iter){ \n",
    "  # Function for MCMC-Metripolis-Hastings-analogue exploration of the nodes ordering space. Return a list with the full MCMC-chain and the best element of the chain. Each element is a list of: nodes vector, dag of best network according to K2, K2-score of such best DAG\n",
    "  # Arguments:\n",
    "  # - proposal_generator: a function like uniform_transposition_generator, that given an ordering, randomly samples a new ordering according to some distribution on the permutation space\n",
    "  # - score_function: a function like k2_algorithm, that given an ordering and data, gives as output the list(network,score) of the corresponding best bayesian network\n",
    "  # - data_df: dataset as a dataframe\n",
    "  # - n_iter: number of random samples from permutation space\n",
    "  nodes<-names(data_df)\n",
    "  chain<-vector('list', n_iter)\n",
    "  best_network<-score_function(data_df)\n",
    "  best_score<-best_network[['score']]\n",
    "  chain[[1]]<-list(nodes=nodes, dag=best_network[['dag']], score=best_score)\n",
    "  old_best_score<-best_score\n",
    "  \n",
    "  for(i in 2:n_iter){\n",
    "    \n",
    "    proposal_nodes<-proposal_generator(nodes)\n",
    "    proposal_data_df <- data_df |> select(all_of(proposal_nodes))\n",
    "    proposal_best_network<-score_function(proposal_data_df)\n",
    "    proposal_best_score<-proposal_best_network[['score']]\n",
    "    \n",
    "    if(runif(1) < min(1, exp(best_score-old_best_score))){ #we take exponential because we are dealing with log of probabilities\n",
    "      nodes<-proposal_nodes\n",
    "      best_network<-proposal_best_network\n",
    "    }\n",
    "    chain[[i]]<-list(nodes=nodes, dag=best_network[['dag']], score=best_network[['score']])\n",
    "  }\n",
    "  max_index<-which.max(lapply(chain, function(el)(el[['score']])))\n",
    "  return(list(chain=chain, best=chain[[max_index]]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34a5ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "n_iter<-5\n",
    "start.time<-proc.time()\n",
    "bn_mcmc_result<-bn_mcmc(ztbinom_permutation_generator, k2_algorithm, sachs, n_iter)\n",
    "end.time<-proc.time()\n",
    "cat('bn_mcmc duration',n_iter, 'iterations: ', end.time-start.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa902b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "saveRDS(bn_mcmc_result, file=rds_name('mcmc_ztbin'))\n",
    "object.size(bn_mcmc_result[['chain']])\n",
    "network_dag<-bn_mcmc_result[['best']][['dag']]\n",
    "chain_scores<-sapply(bn_mcmc_result[['chain']], function(el)(el[['score']]))\n",
    "chain_nodes_orderings<-lapply(bn_mcmc_result[['chain']], function(el)(el[['nodes']]))\n",
    "print(bn_mcmc_result[['best']][['score']])\n",
    "print_network(network_dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9468120",
   "metadata": {},
   "source": [
    "### Function to study how the maximum score obtained in the ordering search increases with the length of the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d38222",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "print_scores_vs_ordering<-function(chain_scores, chain_nodes_orderings){\n",
    "  # Sample data\n",
    "  y <- chain_scores\n",
    "  x <- chain_nodes_orderings\n",
    "  #print(x)\n",
    "  \n",
    "  # Convert character vectors to single strings\n",
    "  labels <- sapply(x, function(vec) paste(vec, collapse = \" \"))\n",
    "  \n",
    "  # Create a basic plot\n",
    "  plot(y, xaxt = \"n\", xlab = \"Nodes permutations\", ylab = \"Best score\", pch = 19, xlim = c(0,length(x)), ylim = c(min(chain_scores), max(chain_scores)))\n",
    "  \n",
    "  # Add custom x-axis labels\n",
    "  #axis(1, at = seq_along(y), labels = labels, las = 2)  # las = 2 rotates labels vertically\n",
    "}\n",
    "print_scores_vs_ordering <- function(chain_scores, chain_nodes_orderings, logscale=FALSE) {\n",
    "  # Sample data\n",
    "  y <- chain_scores\n",
    "  x <- chain_nodes_orderings\n",
    "  \n",
    "  # Convert character vectors to single strings\n",
    "  labels <- sapply(x, function(vec) paste(vec, collapse = \" \"))\n",
    "  \n",
    "  # Set graphical parameters\n",
    "  par(mgp = c(2, 0.5, 0))  # Adjust mgp to reduce space (default is c(3, 1, 0))\n",
    "  \n",
    "  \n",
    "  plot(1:length(y),y, xaxt = \"s\", xlab = \"\", ylab = \"Best score (log)\", \n",
    "       pch = 19, xlim = c(0, length(x)), ylim = c(min(chain_scores), max(chain_scores)))\n",
    "  \n",
    "  \n",
    "  # Manually add x-axis label with fine-tuned position using mtext()\n",
    "  mtext(\"Nodes permutations\", side = 1, line = 1.5)\n",
    "  # Add custom x-axis labels\n",
    "  #axis(1, at = seq_along(y), labels = labels, las = 2)  # las = 2 rotates labels vertically\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "max_score_vs_iter<-function(chain_scores, logscale=FALSE){ \n",
    "  if(logscale){\n",
    "    plot(1:length(chain_scores),cummax(chain_scores),xlab='n iterations (logscale)',ylab='Running max score (log)',col='blue',type='l', log='x') \n",
    "  }else{\n",
    "    plot(1:length(chain_scores),cummax(chain_scores),xlab='n iterations',ylab='Running max score (log)',col='blue',type='l') \n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "print_scores_vs_ordering(chain_scores, chain_nodes_orderings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "max_score_vs_iter(chain_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c14f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "bic_score<-function(dag, data){\n",
    "  return(score(dag , data = data , type = \"bic\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c3b5a",
   "metadata": {},
   "source": [
    "### Function to compare the ground truth expected DAG's with the predicted DAG's as function of the length of the ordering search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "errors_vs_iter<-function(chain_scores,true_dag,chain_dags){  \n",
    "  # Function to compare the ground truth expected DAG's with the predicted DAG's as function of the length of the ordering search. Return vector of errors evaluated by f1_error function\n",
    "  \n",
    "  n_true_edges<-nrow(arcs(true_dag)) \n",
    "  # helper function to find the index of the cummax \n",
    "   \n",
    "  find_index<-function(max_value,chain_scores){ \n",
    "      index<-which(chain_scores==max_value) \n",
    "      return(index) \n",
    "  } \n",
    "  \n",
    "  #compare_dags helper function between the i-th network and true network \n",
    "  compare_dags <- function(index,true_dag, our_nets, n_true_edges=NULL) { \n",
    "      if(is.null(n_true_edges)){\n",
    "        n_true_edges<-nrow(arcs(true_dag)) \n",
    "      }\n",
    "      our_net<-our_nets[[index]] \n",
    "      our_dag<-create_bn_dag(our_net) \n",
    "      return(f1_error(our_dag, true_dag, n_true_edges=n_true_edges))\n",
    "      #dag_shd <- shd(true_dag, our_dag) \n",
    "   \n",
    "  } \n",
    "   \n",
    "  indexes<-sapply(cummax(chain_scores),find_index,chain_scores) \n",
    "   \n",
    "  #perform the comparison once the index is retrieved \n",
    "  errors<-sapply(indexes,function(index, true_dag, our_nets)(compare_dags(index, true_dag, our_nets, n_true_edges = n_true_edges)),true_dag,our_nets=chain_dags) \n",
    "  plot(1:length(errors),errors,xlab='Iteration',ylab='Error',type='l',col='blue') \n",
    "  return(errors) \n",
    " \n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c81731",
   "metadata": {},
   "source": [
    "### Now we proceed running the searches and storing the results for the different settings presented, and then we show some plots obtained from them.\n",
    "\n",
    "Unconstrained parents: mcmc and uniform sampling of nodes ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a497e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "unconstrained_bn_mcmc_results<-setNames(vector(\"list\", 3), c(\"asia\", \"child\", \"sachs\"))\n",
    "UBMR<-unconstrained_bn_mcmc_results\n",
    "for( dataset_name in c('asia','child','sachs')){\n",
    "  n_iter<-1000\n",
    "  start.time<-proc.time()\n",
    "  UBMR[[dataset_name]]<-bn_mcmc(ztbinom_permutation_generator, k2_algorithm, datasets[[dataset_name]], n_iter)\n",
    "  end.time<-proc.time()\n",
    "  cat('bn_mcmc', dataset_name ,'duration',n_iter, 'iterations: ', end.time-start.time)\n",
    "}\n",
    "saveRDS(UBMR, file=rds_name('UBMR'))\n",
    "\n",
    "unconstrained_bn_uniform_results<-setNames(vector(\"list\", 3), c(\"asia\", \"child\", \"sachs\"))\n",
    "UBUR<-unconstrained_bn_uniform_results\n",
    "for( dataset_name in c('asia','child','sachs')){\n",
    "  n_iter<-1000\n",
    "  start.time<-proc.time()\n",
    "  UBUR[[dataset_name]]<-bn_uniform(k2_algorithm, datasets[[dataset_name]], n_iter)\n",
    "  end.time<-proc.time()\n",
    "  cat('bn_uniform', dataset_name ,'duration',n_iter, 'iterations: ', end.time-start.time)\n",
    "}\n",
    "saveRDS(UBUR, file=rds_name('UBUR'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e83db",
   "metadata": {},
   "source": [
    "Constrained max parents: mcmc and uniform sampling of nodes ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73e9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "constrained_bn_mcmc_results<-setNames(vector(\"list\", 3), c(\"asia\", \"child\", \"sachs\"))\n",
    "CBMR<-constrained_bn_mcmc_results\n",
    "for( dataset_name in c('asia','child','sachs')){\n",
    "  n_iter<-1000\n",
    "  start.time<-proc.time()\n",
    "  CBMR[[dataset_name]]<-bn_mcmc(ztbinom_permutation_generator, function(data)(k2_algorithm(data, max_parents = true_max_parents[[dataset_name]])), datasets[[dataset_name]], n_iter)\n",
    "  end.time<-proc.time()\n",
    "  cat('bn_mcmc', dataset_name ,'duration',n_iter, 'iterations: ', end.time-start.time)\n",
    "}\n",
    "saveRDS(CBMR, file=rds_name('CBMR'))\n",
    "\n",
    "constrained_bn_uniform_results<-setNames(vector(\"list\", 3), c(\"asia\", \"child\", \"sachs\"))\n",
    "CBUR<-constrained_bn_uniform_results\n",
    "for( dataset_name in c('asia','child','sachs')){\n",
    "  n_iter<-1000\n",
    "  start.time<-proc.time()\n",
    "  CBUR[[dataset_name]]<-bn_uniform(function(data)(k2_algorithm(data, max_parents = true_max_parents[[dataset_name]])), datasets[[dataset_name]], n_iter)\n",
    "  end.time<-proc.time()\n",
    "  cat('bn_uniform', dataset_name ,'duration',n_iter, 'iterations: ', end.time-start.time)\n",
    "}\n",
    "saveRDS(CBUR, file=rds_name('CBUR'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217de29f",
   "metadata": {},
   "source": [
    "## Let's start from a constrained max number of parents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e07e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Loading them after having saved them. (Proceeding this way allowed us to actually ran the previous code in different computers for speeding up the computations, and then analyse all the results in this notebook)\n",
    "\n",
    "readCBMR<-readRDS('CBMR1725155339414.54.rds')\n",
    "readCBUR<-readRDS('CBUR1725164868090.98.rds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748065be",
   "metadata": {},
   "source": [
    "PLOTS ON RESULTS OF THE ORDERING SEARCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "C_errors_vs_iter_pack<-list(CBMR= setNames(vector(\"list\", length(dataset_names)), dataset_names), \n",
    "                          CBUR=setNames(vector(\"list\", length(dataset_names)), dataset_names))\n",
    "C_sea_res_rds_s<-list(CBMR=readCBMR, CBUR=readCBUR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b8a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "extract_auxiliary_1<-function(errors_vs_iter_pack, sea_res_rds_s){\n",
    "  # Auxiliary function for handy extraction and manipulation of saved results\n",
    "  \n",
    "  options(paged.print = FALSE)\n",
    "  for(sea_res_name in base::names(sea_res_rds_s)){\n",
    "    sea_res_rds<-sea_res_rds_s[[sea_res_name]]\n",
    "    for(dataset_name in dataset_names){\n",
    "      sea_res<-sea_res_rds[[dataset_name]]\n",
    "      print(str(sea_res))\n",
    "      object.size(sea_res[['chain']])\n",
    "      print(network_dag<-sea_res[['best']][['dag']])\n",
    "      chain_scores<-sapply(sea_res[['chain']], function(el)(el[['score']]))\n",
    "      chain_dags<-lapply(sea_res[[\"chain\"]],function(el)(el[[\"dag\"]]))\n",
    "      chain_nodes_orderings<-lapply(sea_res[['chain']], function(el)(el[['nodes']]))\n",
    "      cat('best score: ', sea_res[['best']][['score']])\n",
    "      #print_network(network_dag)\n",
    "      plot_dag(network_dag)\n",
    "      graphviz.compare(true_dags[[dataset_name]], create_bn_dag(network_dag))\n",
    "      print_scores_vs_ordering(chain_scores, chain_nodes_orderings)\n",
    "      max_score_vs_iter(chain_scores, logscale=TRUE)\n",
    "      #my_best_bic<-bic_score(create_bn_dag(network_dag), datasets[[dataset_name]])\n",
    "      #true_best_bic<-bic_score(true_dags[[dataset_name]], datasets[[dataset_name]])\n",
    "      #cat('bic best predicted: ',my_best_bic , 'bic best expected: ',true_best_bic)\n",
    "      errors_vs_iter_pack[[sea_res_name]][[dataset_name]]<-errors_vs_iter(chain_scores, true_dags[[dataset_name]], chain_dags)\n",
    "    }\n",
    "  }\n",
    "  return(errors_vs_iter_pack)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "plot_auxiliary_1<-function(sea_res_name, errors_vs_iter_pack){\n",
    "  # Auxiliary function for plotting results of different datasets on same plot\n",
    "  \n",
    "  # sea_res_name is for example 'CBMR'\n",
    "  # Set graphical parameters\n",
    "  par(mgp = c(1.5, 0.5, 0))  # Adjust mgp to reduce space (default is c(3, 1, 0)) \n",
    "  \n",
    "  ypack<-errors_vs_iter_pack[[sea_res_name]]\n",
    "  \n",
    "  endrange <- length(ypack[[1]])\n",
    "  # Plot the 'asia' dataset with filled dots \n",
    "  plot(1:endrange,  \n",
    "       ypack[['asia']][1:endrange],  \n",
    "       type='l',  \n",
    "       ylim=c(min(unlist(ypack)), max(unlist(ypack))),  \n",
    "       ylab=\"Error\",  \n",
    "       xlab=\"n iterations\",  \n",
    "       col='goldenrod',  \n",
    "       pch=16)  # pch=16 for filled circles \n",
    "   \n",
    "  # Loop through and add lines for 'child' and 'sachs' with filled dots \n",
    "  for(dataset_name in c('child', 'sachs') ) { \n",
    "    lines(1:endrange,  \n",
    "          ypack[[dataset_name]][1:endrange],  \n",
    "          col=dataset_colors[[dataset_name]],  \n",
    "          type='l',  \n",
    "          pch=16)  # pch=16 for filled circles \n",
    "  } \n",
    "  \n",
    "  # Add legend with matching colors \n",
    "  legend(x='topright', legend=c('asia', 'child', 'sachs'), col=c('goldenrod', 'seagreen', 'firebrick'), lty=1, pch=16)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac31f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "C_errors_vs_iter_pack<-extract_auxiliary_1(C_errors_vs_iter_pack, C_sea_res_rds_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c355212f",
   "metadata": {},
   "source": [
    "Constrained number of parents, MCMC search (with ztbinom_generator as proposal generator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0992521",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "plot_auxiliary_1('CBMR', C_errors_vs_iter_pack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcbc342",
   "metadata": {},
   "source": [
    "Constrained number of parents, uniform search in the permuatation space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b914446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "plot_auxiliary_1('CBUR', C_errors_vs_iter_pack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e8a99",
   "metadata": {},
   "source": [
    "## And finally an unconstrained number of parents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9670e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "readUBMR<-readRDS('UBMR1725165402263.55.rds')\n",
    "readUBUR<-readRDS('UBUR1725182729436.31.rds') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e7822",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "U_errors_vs_iter_pack<-list(UBMR= setNames(vector(\"list\", length(dataset_names)), dataset_names), \n",
    "                          UBUR=setNames(vector(\"list\", length(dataset_names)), dataset_names))\n",
    "U_sea_res_rds_s<-list(UBMR=readUBMR, UBUR=readUBUR)\n",
    "\n",
    "U_errors_vs_iter_pack<-extract_auxiliary_1(U_errors_vs_iter_pack, U_sea_res_rds_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca503a89",
   "metadata": {},
   "source": [
    "Unconstrained number of parents, MCMC search (with ztbinom_generator as proposal generator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c79d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "plot_auxiliary_1('UBMR', U_errors_vs_iter_pack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3cd92e",
   "metadata": {},
   "source": [
    "Unconstrained number of parents, uniform search in the permuatation space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "plot_auxiliary_1('UBUR', U_errors_vs_iter_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382aebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "save.image(file = \"/home/ema/Uni/AdvancedStats/Project/SavedRSessions/my_session.RData\") "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
